{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing a rule-based system\n",
    "\n",
    "## Context\n",
    "\n",
    "This notebook is meant to drive you through the usage of Corleone and Express, two softwares developed at the Joint Research Center (European Commission, Ispra, Italy) by Jakub Piskorski. These softwares are in use in production applications, notably the Europe Media Monitor. They are free for academic usage but you should ask a license if you want to use them beyond this tutorial.\n",
    "\n",
    "## Tools\n",
    "\n",
    "- **Corleone** (Core Linguistic Entity Online Extraction) is a set of lightweight linguistic processing components (text scanner, tokenizer, sentence splitter, morphological analysis and gazetteer lookup).\n",
    "- **Express** (Extraction Pattern Recognition Engine and Specification Suite) is an information extraction grammar engine, which consists of a grammar parser and a grammar interpreter.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "We will not manage to do build a full information extraction pipeline within the allocated time (we would need at leat a week!). Here the objective is to **give you an idea** of how things work. We will therefore focus on 2 components: Gazetteers and Grammar, trying to build a small engine to recognize (some) person names. We will rely on an already compiled tokeniser. You will develop a person name gazetteer, and 2 or 3 grammar rules relying on it. Let's get started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Folder structure\n",
    "\n",
    "In both corleone and express repositories, you will find the following structures:\n",
    "\n",
    "```bash \n",
    ".\n",
    "├── compiled-resources # this is where your compiled resources will go\n",
    "├── documentation # user-guide is available here\n",
    "├── experiments # a playground folder, already with some inputs\n",
    "│   ├── input\n",
    "│   └── output\n",
    "├── resources # the 'row' resources, i.e. gazetteers and grammar file before they get compiled\n",
    "└── scripts # the scripts to use to compile or apply the components\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the JARs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the URL to insert in this variable will be communicated\n",
    "# during the workshop as the tool license does not allow us to\n",
    "# further distribute it (i.e. putting it on GitHub)\n",
    "download_link = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-07-09 11:13:04--  https://filesender.switch.ch/filesender/download.php?vid=367de57b-dd7b-f828-0a16-00004c01ecfc\n",
      "Resolving filesender.switch.ch (filesender.switch.ch)... 86.119.34.170\n",
      "Connecting to filesender.switch.ch (filesender.switch.ch)|86.119.34.170|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2220575 (2.1M) [application/octet-stream]\n",
      "Saving to: ‘../libraries.zip’\n",
      "\n",
      "../libraries.zip    100%[===================>]   2.12M   223KB/s    in 13s     \n",
      "\n",
      "2019-07-09 11:13:18 (169 KB/s) - ‘../libraries.zip’ saved [2220575/2220575]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget {download_link} -O ../libraries.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ../libraries.zip\n",
      "  inflating: ../lib-rulebased/brics_automaton.jar  \n",
      "  inflating: ../lib-rulebased/corleone_6_20_2019.jar  \n",
      "  inflating: ../lib-rulebased/express_6_20_2019.jar  \n",
      "  inflating: ../lib-rulebased/log4j-1.2.16.jar  \n"
     ]
    }
   ],
   "source": [
    "!unzip ../libraries.zip -d ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp ../lib-rulebased/*.jar ../rule-based/lib/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '../libraries.zip': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "# clean up\n",
    "! rm -r ../lib-rulebased/\n",
    "! rm ../libraries.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CORLEONE: creating, compiling and applying a gazetteer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first exercise, we will create a small gazetteer for person names.\n",
    "\n",
    "> The CorLEONE gazetteer look-up (dictionary look-up) component matches an input stream of characters or tokens against a gazetteer (dictionary) list, and produces an adequate annotation for the matched text fragment. It allows for associating each entry in the gazetteer with a list of arbitrary flat attribute-value pairs*. (Corleone documentation, Piskorski, 2018.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a person name gazetteer\n",
    "\n",
    "The resources you need to manipulate are under the repository `resources`:\n",
    "\n",
    "- The **raw gazetteer file**, e.g. `person_name_gazetteer.txt`, is the entry file you need to edit with gazetteers elements. Each line represents a single gazetteer entry in the following format: `keyword (attribute:value)+`. \n",
    "\n",
    "```bash\n",
    "# Example of gazetteer, one entry per line, where the input separator is \"|\",\n",
    "# and the attribute/value separator is \":\"\n",
    "New York | GTYPE:location | SUBTYPE:city | CONTINENT: north america\n",
    "G. Bush  | GTYPE: person | SUBTYPE: politician | position: president \n",
    "# => here we are declaring that the string \"New York\" has the GTYPE 'location', the SUBTYPE 'city', etc.\n",
    "\n",
    "# for ambiguous forms, one line per referent:\n",
    "Washington | GTYPE:city | LOCATION:USA | SUBTYPE:cap_city \n",
    "Washington | GTYPE:person | GENDER:m_f \n",
    "Washington | GTYPE:organization | SUBTYPE:commercial \n",
    "Washington | GTYPE:region | LOCATION:US\n",
    "```\n",
    "\n",
    "- The **attribute file** lists all attribute names, where each line stands for a single attribute name. \n",
    "\n",
    "  ```bash\n",
    "  # for our gazetteer above, we need to declare the following types:\n",
    "  GTYPE\n",
    "  SUBTYPE\n",
    "  CONTINENT\n",
    "  LOCATION\n",
    "  GENDER\n",
    "  # => this are the types with which we want to describe our gazetteer entries\n",
    "  ```\n",
    "  \n",
    "- The **type file** (optional) can be used in order to facilitate more strict encoding of the gazetteer entries in order to specify: (a) an attribute that is used to encode the type of the entry, which has to be provided in all entries in the entry file, and (b) a list of appropriate attributes for each type.\n",
    "\n",
    "  ```bash\n",
    "  # for our example above, the type file would contain:\n",
    "  GTYPE # means that all entries need this type, and they can have 'city', 'person' or 'region' as values\n",
    "  city location subtype # means that if an entry is of GTYPE city, it can have the 'location' and 'subtype' attributes\n",
    "  person gender subtype position \n",
    "  region location\n",
    "  \n",
    "  # this is more specific than the type file, this is to declare the possible values for each type.\n",
    "  # this is not mandatory, we can skip it for our exercise.\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling a person name gazetteer \n",
    "\n",
    "A very small person name gazetteer already exists. Let's try to use it.\n",
    "\n",
    "`<digression type'short'>`\n",
    "\n",
    "**What's going on?** In the cells below we are using a special syntax to run **bash** commands (e.g. `cd`, `ls -la`, etc.) **from within** the notebook.\n",
    "\n",
    "By using the `!` prefix at the beginning of a line we tell Jupyter than the line content should be interpreted and executed as a bash command (rather than a Python statement).\n",
    "\n",
    "`</digression>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTEBOOK_HOME = os.path.expanduser(\"~/notebooks/\")\n",
    "CORLEONE_RESOURCES_DIR = os.path.expanduser(\"~/rule-based/corleone/resources/\")\n",
    "CORLEONE_SCRIPTS_DIR = os.path.expanduser(\"~/rule-based/corleone/scripts/\")\n",
    "CORLEONE_COMPILED_RESOURCES = os.path.expanduser(\"~/rule-based/corleone/compiled-resources/\")\n",
    "EXPERIMENTS_INPUT_DIR = os.path.expanduser(\"~/rule-based/corleone/experiments/\")\n",
    "EXPERIMENTS_OUTPUT_DIR = os.path.expanduser(\"~/rule-based/corleone/experiments/output/\")\n",
    "# TODO: add other dirs here below and change to ~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 36\n",
      "drwxr-xr-x 1 jovyan jovyan 4096 Jul  9 06:42 .\n",
      "drwxr-xr-x 1 jovyan jovyan 4096 Jul  9 06:42 ..\n",
      "-rwxr-xr-x 1 jovyan jovyan   24 Jul  9 06:42 PersonNameAttributes.txt\n",
      "-rwxr-xr-x 1 jovyan jovyan  392 Jul  9 06:42 person_name_gaz_application.cfg\n",
      "-rwxr-xr-x 1 jovyan jovyan  334 Jul  9 06:42 person_nameGazetteer.cfg\n",
      "-rwxr-xr-x 1 jovyan jovyan 7895 Jul  9 06:42 person_name_gazetteer.txt\n",
      "-rwxr-xr-x 1 jovyan jovyan  105 Jul  9 06:42 types.txt\n",
      "\n",
      "John| GTYPE>gaz_given_name | SURFACE>John\n",
      "Philip| GTYPE>gaz_given_name | SURFACE>Philip\n",
      "Edward| GTYPE>gaz_given_name | SURFACE>Edward\n",
      "\n",
      "A | GTYPE>gaz_initial | SURFACE>A\n",
      "B | GTYPE>gaz_initial | SURFACE>B\n",
      "C | GTYPE>gaz_initial | SURFACE>C\n",
      "D | GTYPE>gaz_initial | SURFACE>D\n",
      "E | GTYPE>gaz_initial | SURFACE>E\n"
     ]
    }
   ],
   "source": [
    "# go in the resource folder and look at the person_name_gazetteer.txt file\n",
    "os.chdir(CORLEONE_RESOURCES_DIR)\n",
    "! ls -la\n",
    "! head person_name_gazetteer.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the configuration files if you wish: they are already ready, you do not need to edit them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go in the /scripts folder of corleone\n",
    "os.chdir(CORLEONE_SCRIPTS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-07-09 11:18:20,712: INFO main it.jrc.lt.core.component.Component - Create an instance of: basicGazetteer\n",
      "2019-07-09 11:18:20,725: INFO main it.jrc.lt.core.component.Component - Read configuration from file: ../resources/person_nameGazetteer.cfg\n",
      "2019-07-09 11:18:20,728: INFO main it.jrc.lt.core.component.Component - Compile resources\n",
      "2019-07-09 11:18:20,729: INFO main it.jrc.lt.core.component.Component - Read gazetteer resources from file\n",
      "2019-07-09 11:18:20,729: INFO main it.jrc.lt.core.component.Component - Reading attributes from: ../resources/PersonNameAttributes.txt\n",
      "2019-07-09 11:18:20,731: INFO main it.jrc.lt.core.component.Component - Reading entries from: ../resources/person_name_gazetteer.txt\n",
      "2019-07-09 11:18:20,732: INFO main it.jrc.lt.core.component.Component - Building the gazetteer\n",
      "2019-07-09 11:18:20,732: INFO main it.jrc.lt.core.component.Component - Constructing the gazetteer\n",
      "2019-07-09 11:18:20,732: INFO main it.jrc.lt.core.component.Component - Analyzing the entries\n",
      "2019-07-09 11:18:20,732: INFO main it.jrc.lt.core.component.Component - Trimming entries started\n",
      "2019-07-09 11:18:20,736: INFO main it.jrc.lt.core.component.Component - Sort the entries\n",
      "2019-07-09 11:18:20,737: INFO main it.jrc.lt.core.component.Component - Checking if the type definition file exists and analyzing it\n",
      "2019-07-09 11:18:20,737: INFO main it.jrc.lt.core.component.Component - No type definition file provided\n",
      "2019-07-09 11:18:20,737: INFO main it.jrc.lt.core.component.Component - Analyzing and setting the attributes\n",
      "2019-07-09 11:18:20,737: INFO main it.jrc.lt.core.component.Component - Analyze attributes and create mappings\n",
      "2019-07-09 11:18:20,738: INFO main it.jrc.lt.core.component.Component - Create mapping: Number -> Attribute value\n",
      "2019-07-09 11:18:20,740: INFO main it.jrc.lt.core.component.Component - Compressing the entries\n",
      "2019-07-09 11:18:20,741: INFO main it.jrc.lt.core.component.Component - Create new representation for Gazetteer entries.\n",
      "2019-07-09 11:18:20,744: INFO main it.jrc.lt.core.component.Component - Constructing the automaton\n",
      "2019-07-09 11:18:20,744: INFO main it.jrc.lt.core.component.Component - Gazetteer automaton construction\n",
      "2019-07-09 11:18:20,909: INFO main it.jrc.lt.core.component.Component - Gazetteer automaton compression\n",
      "2019-07-09 11:18:20,925: INFO main it.jrc.lt.core.component.Component - Some Initializations\n",
      "2019-07-09 11:18:20,925: INFO main it.jrc.lt.core.component.Component - Gazetteer Information\n",
      "2019-07-09 11:18:20,925: INFO main it.jrc.lt.core.component.Component - Number of Entries: 180\n",
      "2019-07-09 11:18:20,926: INFO main it.jrc.lt.core.component.Component - Number of Attributes: 3\n",
      "2019-07-09 11:18:20,926: INFO main it.jrc.lt.core.component.Component - Average Line length in gazetteer sources: 40\n",
      "2019-07-09 11:18:20,929: INFO main it.jrc.lt.core.component.Component - Formation pattern applicability: 1.0\n",
      "2019-07-09 11:18:20,929: INFO main it.jrc.lt.core.component.Component - #String-valued Attributes: 2\n",
      "2019-07-09 11:18:20,930: INFO main it.jrc.lt.core.component.Component - Write compiled resources to file: ../compiled-resources/person_names.gaz\n",
      "2019-07-09 11:18:20,931: INFO main it.jrc.lt.core.component.Component - Compilation successfull.\n",
      "2019-07-09 11:18:20,931: INFO main it.jrc.lt.core.component.Component - Compilation time: 0.203 secs\n"
     ]
    }
   ],
   "source": [
    "# execute the 'compile component script' with the component alias (basicGazetteer)\n",
    "# and the component configuration file (located in the resource folder)\n",
    "\n",
    "component_alias = \"basicGazetteer\"\n",
    "component_config_file = \"../resources/person_nameGazetteer.cfg\"\n",
    "\n",
    "! ./compileComp.sh {component_alias} {component_config_file}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 740\r\n",
      "drwxr-xr-x 1 jovyan jovyan   4096 Jul  9 11:18 .\r\n",
      "drwxr-xr-x 1 jovyan jovyan   4096 Jul  9 06:42 ..\r\n",
      "-rwxr-xr-x 1 jovyan jovyan 131306 Jul  9 06:42 BasicScanner_EN.bsc\r\n",
      "-rwxr-xr-x 1 jovyan jovyan 131112 Jul  9 06:42 BasicTokenizer.btk\r\n",
      "-rwxr-xr-x 1 jovyan jovyan 469326 Jul  9 06:42 ClassifyingTokenizer_EN.tok\r\n",
      "-rw-r--r-- 1 jovyan jovyan   1781 Jul  9 11:18 person_names.gaz\r\n"
     ]
    }
   ],
   "source": [
    "# go in the compiled resources and check if your compiled component is there\n",
    "os.chdir(CORLEONE_COMPILED_RESOURCES)\n",
    "! ls -la"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply the compiled gazetteer to some inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 44\r\n",
      "drwxr-xr-x 1 jovyan jovyan 4096 Jul  9 06:42 \u001b[0m\u001b[01;34m.\u001b[0m/\r\n",
      "drwxr-xr-x 1 jovyan jovyan 4096 Jul  9 06:42 \u001b[01;34m..\u001b[0m/\r\n",
      "-rwxr-xr-x 1 jovyan jovyan 1079 Jul  9 06:42 \u001b[01;32mbasicTokenizerInput.txt\u001b[0m*\r\n",
      "-rwxr-xr-x 1 jovyan jovyan   10 Jul  9 06:42 \u001b[01;32mclassifyingTokenizerInput1.txt\u001b[0m*\r\n",
      "-rwxr-xr-x 1 jovyan jovyan 1079 Jul  9 06:42 \u001b[01;32mclassifyingTokenizerInput2.txt\u001b[0m*\r\n",
      "drwxr-xr-x 1 jovyan jovyan 4096 Jul  9 06:42 \u001b[01;34moutput\u001b[0m/\r\n",
      "-rwxr-xr-x 1 jovyan jovyan   68 Jul  9 06:42 \u001b[01;32mperson_gazetteer_input.txt\u001b[0m*\r\n",
      "-rwxr-xr-x 1 jovyan jovyan   62 Jul  9 06:42 \u001b[01;32msample_person_names_1.txt\u001b[0m*\r\n",
      "-rwxr-xr-x 1 jovyan jovyan  298 Jul  9 06:42 \u001b[01;32msample_person_names_2.txt\u001b[0m*\r\n",
      "-rwxr-xr-x 1 jovyan jovyan 1554 Jul  9 06:42 \u001b[01;32msentenceSplitterInput1.txt\u001b[0m*\r\n"
     ]
    }
   ],
   "source": [
    "ls -la {EXPERIMENTS_INPUT_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Roberta Mugabe\r",
      "\r\n",
      "Robertem Mugabe\r",
      "\r\n",
      "Robercie Mugabe\r",
      "\r\n",
      "Mugabe Roberta\r",
      "\r\n",
      "G. Pilarz\r",
      "\r\n",
      "Pilarz Grzegorz\r",
      "\r\n",
      "Grzegorza Pilarza\r",
      "\r\n",
      "Grzegorzowi Pilarzowi\r",
      "\r\n",
      "Grzegorzem Pilarzem\r",
      "\r\n",
      "Grzegorzu Pilarzu\r",
      "\r\n",
      "Trump\r",
      "\r\n",
      "D. Trump\r",
      "\r\n",
      "Donald John Trump\r",
      "\r\n",
      "Donald J. Trump\r",
      "\r\n",
      "Mr. Trump\r",
      "\r\n",
      "Mr. Trump's\r",
      "\r\n",
      "Mr Trump\r",
      "\r\n",
      "Mr Trump's\r",
      "\r\n",
      "Trump's\r",
      "\r\n",
      "Trump Donald\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "! cat {EXPERIMENTS_INPUT_DIR}/sample_person_names_2.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go in the /scripts folder of corleone\n",
    "\n",
    "os.chdir(CORLEONE_SCRIPTS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-07-09 11:18:29,736: INFO main it.jrc.lt.core.component.Component - Create an instance of: basicGazetteer\n",
      "2019-07-09 11:18:29,749: INFO main it.jrc.lt.core.component.Component - Read configuration from file: ../resources/person_name_gaz_application.cfg\n",
      "2019-07-09 11:18:29,751: INFO main it.jrc.lt.core.component.Component - Initialize the instance of: basicGazetteer\n",
      "2019-07-09 11:18:29,823: INFO main it.jrc.lt.core.component.Component - Current Characterset is: UTF-8\n",
      "2019-07-09 11:18:29,823: INFO main it.jrc.lt.core.component.Component - Processing file: /home/jovyan/rule-based/corleone/scripts/../experiments/person_gazetteer_input.txt\n",
      "2019-07-09 11:18:29,832: INFO main it.jrc.lt.core.component.Component - Writing result to the file: ../experiments/output/\\person_gazetteer_input.txt.out\n"
     ]
    }
   ],
   "source": [
    "# execute the 'apply component script' with the component alias\n",
    "# (basicGazetteer) and the component configuration file (located in the resource folder)\n",
    "\n",
    "! ./applyComp.sh basicGazetteer ../resources/person_name_gaz_application.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "journalist [START: 7, END: 16, SURFACE: journalist, GTYPE: gaz_title, GNUMBER: sg]\r\n",
      "----------------------------------\r\n",
      "John [START: 18, END: 21, SURFACE: John, GTYPE: gaz_given_name]\r\n",
      "----------------------------------\r\n",
      "K [START: 23, END: 23, SURFACE: K, GTYPE: gaz_initial]\r\n",
      "----------------------------------\r\n",
      "P [START: 25, END: 25, SURFACE: P, GTYPE: gaz_initial]\r\n",
      "----------------------------------\r\n",
      "Professor [START: 42, END: 50, SURFACE: Professor, GTYPE: gaz_title]\r\n",
      "----------------------------------\r\n"
     ]
    }
   ],
   "source": [
    "# go in the experiment folder and check the output\n",
    "\n",
    "! head '../experiments/output/\\person_gazetteer_input.txt.out'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate \n",
    "\n",
    "Now that you did the first edit-compiling-applying cycle, you can go back to the entry file and add more entries. The information you enter will be used by the grammar rules that you will develop next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Express: Creating, Compiling and Applying a grammar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some explanations\n",
    "\n",
    "\n",
    "For now we will apply a grammar containing 2 rules, which you can already use. The explainations below are to give you some information.\n",
    "\n",
    "A grammar cascade definition consists of three main ingredients:\n",
    "\n",
    "#### Definition of feature structure types*\n",
    "\n",
    "The type specification file contains the types and their attributes which are used in the grammars.\n",
    "It is in this file that you define that you want to create a type 'person' or 'organisation', with their attributes 'firstname' and 'headquarters', for examples.\n",
    "\n",
    "Express has an interface with Corleone components and is able to \"understand\" some of Corleone types by default. For example, Corleone tokenizer has the type \"token\" with the attributes \"type\" and \"surface\".\n",
    "\n",
    "Given our person name gazetteers and the Corleone modules that we use, we define our grammar type file as follows:\n",
    "\n",
    "```\n",
    "basic-token := [SURFACE] # coming from Corleone component\n",
    "token := [TYPE,SURFACE] # coming from Corleone component, a more refined tokenizer\n",
    "person := [NAME,FIRST_NAME,LAST_NAME,INITIAL,TITLE,RULE] # the type we want to manipulate in our preons grammar file\n",
    "gaz_given_name := [SURFACE] # coming from the person gazetteer\n",
    "gaz_title := [GNUMBER,SURFACE] # coming from the person gazetteer\n",
    "gaz_initial := [SURFACE] # coming from the person gazetteer\n",
    "gaz_name_infix := [SURFACE] # coming from the person gazetteer\n",
    "```\n",
    "\n",
    "This file type is already defined in the folder structure of the hands-on, normally there is not need to change nothing (unless you add more types in our gazetteer).\n",
    "\n",
    "#### Set of grammar specifications\n",
    "\n",
    "\n",
    "This is the grammar file per se, which consists of 2 parts:\n",
    "\n",
    "**A. Setting part** \n",
    "\n",
    "**Normally you do not need to change the setting part for the hands-on.**\n",
    "\n",
    "- MODULES: to specify the list of pre-processing modules which will be applied before the grammar interpreter. In our case, we use Corleone modules, including the person gazetteer compiled in the previous step. These pre-processing components provide the grammar interpreter with a stream of input feature structures.\n",
    "\n",
    "- SEARCH_MODE: defines the matchin strategy. Here we choose \"longest match\".\n",
    "\n",
    "- OUTPUT: defines what the interpreter should outputs, its own feature structures (grammar), all the feature structures of all applied components (all), all the feature structures of applied and non-applied conponents (grammar_and_unconsumed).\n",
    "\n",
    "\n",
    "**B. Rule part**\n",
    "\n",
    "**This is the part you might want to update**\n",
    "\n",
    "The part between **PATTERNS** and **END_PATTERNS** contains the rule definitions.\n",
    "\n",
    "#### Set of **rule prioritisation** definition\n",
    "We do not use this part in the hands-on.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a grammar\n",
    "\n",
    "A grammar already exists in our folder, we will try to use it.\n",
    "\n",
    "**Let's first have a look at the grammar file:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining our paths\n",
    "EXPRESS_RESOURCES_DIR = os.path.expanduser(\"~/rule-based/express/resources/\")\n",
    "EXPRESS_SCRIPTS_DIR = os.path.expanduser(\"~/rule-based/express/scripts/\")\n",
    "EXPRESS_COMPILED_RESOURCES = os.path.expanduser(\"~/rule-based/express/compiled-resources/\")\n",
    "EXPRESS_OUTPUT_DIR = os.path.expanduser(\"~/rule-based/express/experiments/output/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we go in the express resource folder\n",
    "os.chdir(EXPRESS_RESOURCES_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%\r\n",
      "% Very basic grammar for person names\r\n",
      "%\r\n",
      "\r\n",
      "SETTINGS:\r\n",
      "\r\n",
      "{\r\n",
      "% Modules (currently used Corleone components)\r\n",
      "% the 'gazetteerPersons' modules will load the gazetteer defined previously\r\n",
      "\r\n",
      "    MODULES: <CorleoneTokenizer>,<CorleoneBasicTokenizer>,<gazetteerPersons>\r\n",
      "\r\n",
      "    %SEARCH_MODE: all_longest_matches\r\n",
      "    SEARCH_MODE: longest_match\r\n",
      "    %SEARCH_MODE: all_match\r\n",
      "    % Output\r\n",
      "\r\n",
      "    OUTPUT: grammar\r\n",
      "}\r\n",
      "\r\n",
      "PATTERNS:\r\n",
      "\r\n",
      "% Example 1\r\n",
      "% This is a basic pattern for detecting person names based on known first names,\r\n",
      "% followed by 1 to 3 first capital words identified thanks to the tokenizer.\r\n",
      "% The surface of identified tokens are kept by defining them as 'variables' in the rule (#last_name).\r\n",
      "% These variable are \"feeding\" a new feature structure \"person\" composed of NAME, FIRST_NAME, LAST_NAME and RULE.\r\n",
      "% The NAME attribute of the type \"person\" is built by aplying a concatenation of the first and last name\r\n",
      "% (thanks to a grammar functional operator called \"ConcWithBlanks\")\r\n",
      "\r\n",
      "\r\n",
      "person_name_rule1  :>  (gaz_given_name & [SURFACE: #base_form]\r\n",
      "                         (token & [TYPE: \"first_capital_word\", SURFACE: #last_name])<1,3>):name\r\n",
      "-> name: person & [NAME: #full_name, FIRST_NAME: #base_form, LAST_NAME: #last_name, RULE: \"person_name_rule1\"]\r\n",
      "& #full_name := ConcWithBlanks(#base_form,#last_name).\r\n",
      "\r\n",
      "\r\n",
      "% Example 2: Director Kowalski or  Director A. Kowalski or Director A. B. Kowalski or Director A. de Kowalski\r\n",
      "% This rule tries to identify person names composed of: a title, recognized thanks to the gazetteer\r\n",
      "% optionally followed by an initial (coming from the gazetteer) plus the token \".\" OR followed by 2 initials (lines 46 to 50)\r\n",
      "% followed by a capitalized token (lines 51-52)\r\n",
      "% followed by an optional infix (line 53)\r\n",
      "% followed by a capitalized token (lines 54-57), identified as the last name\r\n",
      "\r\n",
      "person_name_rule2 :> ((gaz_title & [SURFACE: #title])\r\n",
      "                      ( (gaz_initial & [SURFACE: #initial_1] token & [SURFACE: \".\"])\r\n",
      "                         | (gaz_initial & [SURFACE: #initial_1]\r\n",
      "                            token & [SURFACE: \".\"]\r\n",
      "                            gaz_initial & [SURFACE: #initial_2]\r\n",
      "                            token & [SURFACE: \".\"])) ?\r\n",
      "                      (token & [TYPE: \"first_capital_word\", SURFACE: #first_name]\r\n",
      "                         | token & [TYPE: \"word_with_hyphen_first_capital\", SURFACE: #first_name])\r\n",
      "                      (gaz_name_infix & [SURFACE: #infix]) ?\r\n",
      "                      (token & [TYPE: \"first_capital_word\", SURFACE: #last_name]\r\n",
      "                        | (token & [TYPE: \"mixed_word_first_capital\", SURFACE: #last_name])\r\n",
      "                        | (token & [TYPE: \"word_with_hyphen_first_capital\", SURFACE: #last_name])\r\n",
      "                        | (token & [TYPE: \"word_with_apostrophe_first_capital\", SURFACE: #last_name]))?):name\r\n",
      "-> name: person & [NAME: #full_name, FIRST_NAME: #first_name, LAST_NAME: #last_name_final, INITIAL:#initial, TITLE: #title, RULE: \"person_name_rule2\"]\r\n",
      "& #last_name_final :=ConcWithBlanks(#infix, #last_name)\r\n",
      "& #initial := PersonNameInitial(#initial_1,#initial_2)\r\n",
      "& #full_name := ConcWithBlanks(#initial,#first_name,#infix,#last_name).\r\n",
      "\r\n",
      "\r\n",
      "% Example 3: Try to write a rule which recognizes sequence of: [title - capitalized word - capitalized word]\r\n",
      "\r\n",
      "\r\n",
      "END_PATTERNS:\r\n"
     ]
    }
   ],
   "source": [
    "# we look at the rule file\n",
    "! cat grammar_person_rules_0.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's check the resources of the grammar*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we copy our compiled person gazetteer \".gaz\" into express \n",
    "# compiled resources folder, so that the grammar interpreter an use it.\n",
    "\n",
    "! cp {CORLEONE_COMPILED_RESOURCES}person_names.gaz {EXPRESS_COMPILED_RESOURCES}data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's list our compiled resource folder:**\n",
    "``` bash\n",
    ".\n",
    "├── data # contains the compiled resources, this is where the person gaz and grammar compiled files go.\n",
    "│   ├── BasicTokenizer.btk\n",
    "│   ├── ClassifyingTokenizer_EN.tok\n",
    "│   ├── grammar_person.grm\n",
    "│   ├── person_grammar_types.txt\n",
    "│   └── person_names.gaz\n",
    "└── modules_grammar # contains the configuration for the pre-processing modules, no need to change\n",
    "    ├── basic_tokenizer_configuration.cfg\n",
    "    ├── classifying_tokenizer_configuration.cfg\n",
    "    └── gazetteerPersonConfig.cfg\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's compile our grammar**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(EXPRESS_SCRIPTS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing the type file: ../resources/grammar_person_TypeFile.txt\n",
      "Parsing grammar file: ../resources/grammar_person_rules_0.txt\n",
      "Syntax of the types and grammar files is correct\n",
      "Perform semantic analysis\n",
      "Type file: ../resources/grammar_person_TypeFile.txt\n",
      "Grammar file: ../resources/grammar_person_rules_0.txt\n",
      "Checking grammar\n",
      "Checking output types\n",
      "Checking search mode\n",
      "Checking component names\n",
      "Checking rules\n",
      "Convert each rule to a finite-state representation\n",
      "Converting rule: person_name_rule1\n",
      "Converting rule: person_name_rule2\n",
      "Conversion of rule automata into Rule Filtering automaton\n",
      "Determinisation of Rule Filtering automaton\n",
      "Converting Deterministic Rule Filtering automaton into efficient representation\n",
      "Initialise auxilliary data structures\n",
      "Parsing succesfull\n",
      "There are 0 warnings:\n",
      "Parsing succesfull\n",
      "Compilation succesfull\n"
     ]
    }
   ],
   "source": [
    "! ./runParser.sh ../resources/compilation.cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's see if the grammar file *.grm is in the compiled resources folder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 jovyan   2598 Jul  9 11:18 grammar_person.grm\r\n"
     ]
    }
   ],
   "source": [
    "ll ../compiled-resources/data/ | grep grm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can now apply our grammar on texts**\n",
    "\n",
    "The input folder in experiments contains a small file with some person names. Let's open it:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 64\r\n",
      "drwxr-xr-x 1 jovyan jovyan  4096 Jul  9 06:42 \u001b[0m\u001b[01;34m.\u001b[0m/\r\n",
      "drwxr-xr-x 1 jovyan jovyan  4096 Jul  9 06:42 \u001b[01;34m..\u001b[0m/\r\n",
      "-rw-r--r-- 1 jovyan jovyan  1411 Jul  9 06:42 die-zeit-2019-07-06.txt\r\n",
      "-rw-r--r-- 1 jovyan jovyan 14035 Jul  9 06:42 GDL-1815-02-21-a-i0011-p3.txt\r\n",
      "-rw-r--r-- 1 jovyan jovyan 14189 Jul  9 06:42 GDL-1815-02-21-a-i0011.txt\r\n",
      "-rwxr-xr-x 1 jovyan jovyan   310 Jul  9 06:42 \u001b[01;32mgrammar_person_input.txt\u001b[0m*\r\n",
      "-rw-r--r-- 1 jovyan jovyan  1474 Jul  9 06:42 guardian-2019-07-06.txt\r\n",
      "-rw-r--r-- 1 jovyan jovyan  5445 Jul  9 06:42 JDG-1977-03-24-a-i0080-p11.txt\r\n",
      "-rw-r--r-- 1 jovyan jovyan   460 Jul  9 06:42 luxwort-1938-01-19-a-i0031-p3.txt\r\n"
     ]
    }
   ],
   "source": [
    "ls -la ../experiments/input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Police apprehended Philip Kowalski\r",
      "\r\n",
      "Breaking News: Professor Kowalski was taken into custody by the Ispra Police Department.\r",
      "\r\n",
      "Former President Barack Obama attended the funerals of former President G. W. Bush.\r",
      "\r\n",
      "Dominique de Villepin is about to pronounce a speech at UN Council, journalist Bob Manello reports."
     ]
    }
   ],
   "source": [
    "! cat ../experiments/input/grammar_person_input.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir ../experiments/output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's try to apply the grammar on this file first**. The output will appear on the experiment/output folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-07-09 11:19:30,845: INFO main it.jrc.lt.regexpfs.GrammarInterpreter - Launching the grammar interpreter\n",
      "2019-07-09 11:19:30,846: INFO main it.jrc.lt.regexpfs.GrammarInterpreter - Loading resources started\n",
      "2019-07-09 11:19:30,846: INFO main it.jrc.lt.regexpfs.GrammarInterpreter - Reading configuration properties\n",
      "2019-07-09 11:19:30,846: INFO main it.jrc.lt.regexpfs.GrammarInterpreter - Load cascaded grammar from the file: ../compiled-resources/data/grammar_person.grm\n",
      "2019-07-09 11:19:30,912: INFO main it.jrc.lt.regexpfs.GrammarInterpreter - Initialize modules specified in the module configuration directory: ../compiled-resources/modules_grammar\n",
      "2019-07-09 11:19:30,913: INFO main it.jrc.lt.regexpfs.GrammarInterpreter - Launching module specified in the file: /home/jovyan/rule-based/express/scripts/../compiled-resources/modules_grammar/classifying_tokenizer_configuration.cfg\n",
      "2019-07-09 11:19:31,009: INFO main it.jrc.lt.regexpfs.module.Module - Module named: CorleoneTokenizer has been registered successfully.\n",
      "2019-07-09 11:19:31,009: INFO main it.jrc.lt.regexpfs.GrammarInterpreter - Launching module specified in the file: /home/jovyan/rule-based/express/scripts/../compiled-resources/modules_grammar/basic_tokenizer_configuration.cfg\n",
      "2019-07-09 11:19:31,023: INFO main it.jrc.lt.regexpfs.module.Module - Module named: CorleoneBasicTokenizer has been registered successfully.\n",
      "2019-07-09 11:19:31,023: INFO main it.jrc.lt.regexpfs.GrammarInterpreter - Launching module specified in the file: /home/jovyan/rule-based/express/scripts/../compiled-resources/modules_grammar/gazetteerPersonConfig.cfg\n",
      "2019-07-09 11:19:31,033: INFO main it.jrc.lt.regexpfs.module.Module - gazetteerPersons will be used output types as specified in the file: ../compiled-resources/data/person_grammar_types.txt\n",
      "2019-07-09 11:19:31,039: INFO main it.jrc.lt.regexpfs.module.Module - Module named: gazetteerPersons has been registered successfully.\n",
      "2019-07-09 11:19:31,039: INFO main it.jrc.lt.regexpfs.GrammarInterpreter - 3 MODULES INSTALLED\n",
      "2019-07-09 11:19:31,039: INFO main it.jrc.lt.regexpfs.GrammarInterpreter - CorleoneBasicTokenizer INSTALLED\n",
      "2019-07-09 11:19:31,039: INFO main it.jrc.lt.regexpfs.GrammarInterpreter - CorleoneTokenizer INSTALLED\n",
      "2019-07-09 11:19:31,039: INFO main it.jrc.lt.regexpfs.GrammarInterpreter - gazetteerPersons INSTALLED\n",
      "2019-07-09 11:19:31,039: INFO main it.jrc.lt.regexpfs.GrammarInterpreter - Debugging mode is: ON\n",
      "2019-07-09 11:19:31,039: INFO main it.jrc.lt.regexpfs.GrammarInterpreter - Debugging all grammars mode is: OFF\n",
      "2019-07-09 11:19:31,039: INFO main it.jrc.lt.regexpfs.GrammarInterpreter - Debugging rule statistics is: OFF\n",
      "2019-07-09 11:19:31,040: INFO main it.jrc.lt.regexpfs.GrammarInterpreter - Spliting files into an array of lines is : OFF\n",
      "2019-07-09 11:19:31,040: INFO main it.jrc.lt.regexpfs.GrammarInterpreter - Loading resources ended\n",
      "2019-07-09 11:19:31,040: INFO main it.jrc.lt.regexpfs.GrammarInterpreter - Checking consistency of resources started\n",
      "2019-07-09 11:19:31,040: INFO main it.jrc.lt.regexpfs.GrammarInterpreter - Checking whether module names appearing in the grammar are launched\n",
      "2019-07-09 11:19:31,040: INFO main it.jrc.lt.regexpfs.GrammarInterpreter - Checking whether global types specification is consistent with type specification for each of the launched modules (which will be used)\n",
      "2019-07-09 11:19:31,040: INFO main it.jrc.lt.regexpfs.GrammarInterpreter - Checking consistency of resources ended\n",
      "2019-07-09 11:19:31,040: INFO main it.jrc.lt.regexpfs.GrammarInterpreter - Launching the grammar interpreter completed\n",
      "\n",
      "\n",
      "Number of processed files: 0\n",
      "FILE: --------> /home/jovyan/rule-based/express/scripts/../experiments/input/luxwort-1938-01-19-a-i0031-p3.txt\n",
      "\n",
      "\n",
      "Final result of applying the grammar cascade:\n",
      "----------------------------------------------------\n",
      "\n",
      "Num matches: 0\n",
      "Writing to file: /home/jovyan/rule-based/express/scripts/../experiments/output\\luxwort-1938-01-19-a-i0031-p3.txt-result.txt\n",
      "Processing time: 0.07199999690055847\n",
      "FILE: --------> /home/jovyan/rule-based/express/scripts/../experiments/input/JDG-1977-03-24-a-i0080-p11.txt\n",
      "\n",
      "\n",
      "Final result of applying the grammar cascade:\n",
      "----------------------------------------------------\n",
      "\n",
      "Num matches: 0\n",
      "Writing to file: /home/jovyan/rule-based/express/scripts/../experiments/output\\JDG-1977-03-24-a-i0080-p11.txt-result.txt\n",
      "Processing time: 0.1120000034570694\n",
      "FILE: --------> /home/jovyan/rule-based/express/scripts/../experiments/input/guardian-2019-07-06.txt\n",
      "\n",
      "\n",
      "Final result of applying the grammar cascade:\n",
      "----------------------------------------------------\n",
      "\n",
      "Num matches: 0\n",
      "Writing to file: /home/jovyan/rule-based/express/scripts/../experiments/output\\guardian-2019-07-06.txt-result.txt\n",
      "Processing time: 0.014999999664723873\n",
      "FILE: --------> /home/jovyan/rule-based/express/scripts/../experiments/input/GDL-1815-02-21-a-i0011.txt\n",
      "\n",
      "\n",
      "Final result of applying the grammar cascade:\n",
      "----------------------------------------------------\n",
      "\n",
      "Num matches: 0\n",
      "Writing to file: /home/jovyan/rule-based/express/scripts/../experiments/output\\GDL-1815-02-21-a-i0011.txt-result.txt\n",
      "Processing time: 0.07599999755620956\n",
      "FILE: --------> /home/jovyan/rule-based/express/scripts/../experiments/input/die-zeit-2019-07-06.txt\n",
      "\n",
      "\n",
      "Final result of applying the grammar cascade:\n",
      "----------------------------------------------------\n",
      "\n",
      "Num matches: 0\n",
      "Writing to file: /home/jovyan/rule-based/express/scripts/../experiments/output\\die-zeit-2019-07-06.txt-result.txt\n",
      "Processing time: 0.004000000189989805\n",
      "FILE: --------> /home/jovyan/rule-based/express/scripts/../experiments/input/grammar_person_input.txt\n",
      "\n",
      "\n",
      "Final result of applying the grammar cascade:\n",
      "----------------------------------------------------\n",
      "CONTENT: Philip Kowalski Breaking News \n",
      "POSITION: [19,48]\n",
      "STRUCTURE-TYPE: person\n",
      "FEATURES:\n",
      "NAME=Philip Kowalski Breaking News\n",
      "FIRST_NAME=Philip\n",
      "LAST_NAME=Kowalski Breaking News\n",
      "INITIAL=-\n",
      "TITLE=-\n",
      "RULE=person_name_rule1\n",
      "-----------------------\n",
      "-----------------------\n",
      "CONTENT: Professor Kowalski \n",
      "POSITION: [51,68]\n",
      "STRUCTURE-TYPE: person\n",
      "FEATURES:\n",
      "NAME=Kowalski\n",
      "FIRST_NAME=Kowalski\n",
      "LAST_NAME=\n",
      "INITIAL=\n",
      "TITLE=Professor\n",
      "RULE=person_name_rule2\n",
      "-----------------------\n",
      "-----------------------\n",
      "CONTENT: journalist Bob Manello \n",
      "POSITION: [279,300]\n",
      "STRUCTURE-TYPE: person\n",
      "FEATURES:\n",
      "NAME=Bob Manello\n",
      "FIRST_NAME=Bob\n",
      "LAST_NAME=Manello\n",
      "INITIAL=\n",
      "TITLE=journalist\n",
      "RULE=person_name_rule2\n",
      "-----------------------\n",
      "-----------------------\n",
      "\n",
      "Num matches: 3\n",
      "Writing to file: /home/jovyan/rule-based/express/scripts/../experiments/output\\grammar_person_input.txt-result.txt\n",
      "Processing time: 0.008999999612569809\n",
      "FILE: --------> /home/jovyan/rule-based/express/scripts/../experiments/input/GDL-1815-02-21-a-i0011-p3.txt\n",
      "\n",
      "\n",
      "Final result of applying the grammar cascade:\n",
      "----------------------------------------------------\n",
      "\n",
      "Num matches: 0\n",
      "Writing to file: /home/jovyan/rule-based/express/scripts/../experiments/output\\GDL-1815-02-21-a-i0011-p3.txt-result.txt\n",
      "Processing time: 0.08799999952316284\n",
      "Number documents: 7\n",
      "Modules : 0 : 0.023285714285714288\n",
      "Grammar : 0 : 0.026714285714285715\n",
      "Output : 0 : 0.0014285714285714286\n",
      "Total: 0.049999999999999996\n"
     ]
    }
   ],
   "source": [
    "! ./runInterpreter.sh ../resources/execution.cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's observe the results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Philip Kowalski Breaking News\"\t19\t48\tperson\tNAME\tPhilip Kowalski Breaking News\tFIRST_NAME\tPhilip\tLAST_NAME\tKowalski Breaking News\tRULE\tperson_name_rule1\r\n",
      "\"Professor Kowalski\"\t51\t68\tperson\tNAME\tKowalski\tFIRST_NAME\tKowalski\tLAST_NAME\t\tINITIAL\t\tTITLE\tProfessor\tRULE\tperson_name_rule2\r\n",
      "\"journalist Bob Manello\"\t279\t300\tperson\tNAME\tBob Manello\tFIRST_NAME\tBob\tLAST_NAME\tManello\tINITIAL\t\tTITLE\tjournalist\tRULE\tperson_name_rule2\r\n"
     ]
    }
   ],
   "source": [
    "! cat ../experiments/output\\\\grammar_person_input.txt-result.txt # here there is the same pb with the \"\\\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What you can try next:**\n",
    "\n",
    "- After this first application, try to change the OUTPUT attribute from 'grammar' to 'all' in the grammar file, recompile the grammar and apply it again on the same file. You should see more information in the output file.\n",
    "- move more input files in the \"input\" folder (some examples in different languages are just one level up), and observe the results\n",
    "- try to write a rule to recognize the missed names in ``\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
